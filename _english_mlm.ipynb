{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec7e144-5ab7-4c13-b9b4-bafa2413f0d9",
   "metadata": {},
   "source": [
    "# English masked language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eca706b-8b31-4c7f-907c-19c7c6631e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd86f248-1929-4c1a-aeeb-475db9966528",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tqdmv' from 'tqdm' (/usr/local/lib/python3.8/dist-packages/tqdm/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdmv\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gest, stereotype_names\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bootstrap_ci, set_size, visualize_corr\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'tqdmv' from 'tqdm' (/usr/local/lib/python3.8/dist-packages/tqdm/__init__.py)"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from itertools import combinations, product\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdmv\n",
    "\n",
    "from gest import gest, stereotype_names\n",
    "from utils import bootstrap_ci, set_size, visualize_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79041377-8d92-4d91-894a-ebfca24d7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'bert-base-uncased',\n",
    "    'roberta-base',    \n",
    "    'albert-base-v2',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'xlm-roberta-base',\n",
    "    'xlm-roberta-large',\n",
    "    'facebook/xlm-v-base',\n",
    "    'facebook/xlm-roberta-xl',\n",
    "    'distilbert-base-uncased',\n",
    "    'google/electra-large-generator',\n",
    "    'google/electra-base-generator',\n",
    "]\n",
    "\n",
    "def short_model_name(model):\n",
    "    for s in ('uncased', 'v2', 'cased', 'generator'):\n",
    "        if model.endswith('-' + s):\n",
    "            model = model[:-len(s)-1]\n",
    "    model = model.split('/')[-1]\n",
    "    if model.endswith('lingual'):\n",
    "        model = model[:-7]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3dd6cb-683f-4736-a420-d4ad1b7ab0ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def file_results(filename):\n",
    "    return list(map(float, open(filename, 'r').readlines()))\n",
    "\n",
    "def model_template_file(model, template_id):\n",
    "    model = model.split('/')[-1]\n",
    "    return f'./data/predictions/english_mlm/{model}_template-{template_id}.txt'\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def r_i(filename, stereotype_id, bootstrap=True):\n",
    "    \"\"\"\n",
    "    Average score for stereotype _i_\n",
    "    \"\"\"\n",
    "    vals = [\n",
    "        val\n",
    "        for val, gest_stereotype_id in zip(file_results(filename), gest.stereotype)\n",
    "        if gest_stereotype_id == stereotype_id\n",
    "    ]\n",
    "\n",
    "    if bootstrap:\n",
    "        return bootstrap_ci(vals)\n",
    "    else:\n",
    "        return np.mean(vals)\n",
    "\n",
    "def r_is(filename, bootstrap=True):\n",
    "    \"\"\"\n",
    "    Averages for all 16 stereotypes\n",
    "    \"\"\"\n",
    "    return [r_i(filename, stereotype_id, bootstrap) for stereotype_id in range(1, 17)]\n",
    "\n",
    "def r_f(filename):\n",
    "    \"\"\"\n",
    "    Average score $r_i$ for female stereotypes\n",
    "    \"\"\"\n",
    "    return np.mean([\n",
    "        r_i(filename, stereotype_id, bootstrap=False)\n",
    "        for stereotype_id in range(1, 8)\n",
    "    ]) \n",
    "\n",
    "def r_m(filename):\n",
    "    \"\"\"\n",
    "    Average score $r_i$ for male stereotypes\n",
    "    \"\"\"\n",
    "    return np.mean([\n",
    "        r_i(filename, stereotype_id, bootstrap=False)\n",
    "        for stereotype_id in range(8, 17)\n",
    "    ]) \n",
    "\n",
    "def g_s(filename):\n",
    "    \"\"\"\n",
    "    Overall stereotype rate\n",
    "    \"\"\"\n",
    "    return r_m(filename) - r_f(filename)\n",
    "\n",
    "def r_i_ranks(filename):\n",
    "    return np.argsort(np.argsort(r_is(filename, bootstrap=False))) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df51e4e-c200-4076-a5ae-290f111405fd",
   "metadata": {},
   "source": [
    "## Basic visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20474c98-008d-443b-a2ae-c3c89fe4b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 8, sharey=True)\n",
    "axes = axes.reshape(-1)\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "for ax in axes[-4:]:\n",
    "    ax.remove()\n",
    "\n",
    "for ax, (model, template_id) in zip(axes, product(models, range(4))):\n",
    "    filename = model_template_file(model, template_id)\n",
    "    for stereotype_id in range(1, 17):\n",
    "        _, lower, upper = r_i(filename, stereotype_id)\n",
    "        ax.plot([lower, upper], [stereotype_id, stereotype_id], c=('pink' if stereotype_id < 8 else 'lightblue'))\n",
    "    ax.set_yticks(range(1, 17), stereotype_names)\n",
    "    ax.axvline(r_m(filename), linestyle=':', linewidth=2, color='lightblue')\n",
    "    ax.axvline(r_f(filename), linestyle=':', linewidth=2, color='pink')\n",
    "        \n",
    "    if template_id == 0:\n",
    "        ax.set_ylabel(short_model_name(model))\n",
    "\n",
    "set_size(10, 14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/en_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd3268-b422-49b8-a085-ec08a639c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ci(mean, lower, upper):\n",
    "    return f'{lower:.2f} {mean:.2f} {upper:.2f}'\n",
    "\n",
    "for model in models:\n",
    "    print('\\\\midrule')\n",
    "    print(\"& \\multicolumn{16}{l}{\\\\texttt{\", end='')\n",
    "    print(short_model_name(model), end='')\n",
    "    print(\"}} \\\\\\\\\")\n",
    "    for template_id in range(4):\n",
    "        print(template_id+1, *[\n",
    "            format_ci(*r_i(model_template_file(model, template_id), stereotype_id))\n",
    "            for stereotype_id in range(1, 17)\n",
    "        ], sep=' & ', end=' \\\\\\\\\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a38f2-cbc4-4002-a26b-280014644d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The results are pretty consistent across different templates - This is often not the case with other measures.\n",
    "\n",
    "The only exception is template #3 with BERT and DistilBERT (note that DistilBERT is directly distilled from the original BERT).\n",
    "Not sure why that is the case, but it might simply expect different pronouns there.\n",
    "\"\"\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)\n",
    "\n",
    "for model in models:\n",
    "    rates = [\n",
    "        g_s(model_template_file(model, template_id))\n",
    "        for template_id in range(4)\n",
    "    ]\n",
    "    plt.plot(range(1,6), rates + [np.mean(rates)], marker='o')\n",
    "    model = short_model_name(model)\n",
    "    ver_offset = {'distilbert-base': 0.005, 'xlm-roberta-large': -0.005, 'electra-large': -0.007}.get(model, 0)\n",
    "    plt.text(5 + 0.04, np.mean(rates) + ver_offset, model, fontsize=8, rotation=-30, rotation_mode='anchor')\n",
    "plt.axvline(4.5, linestyle=':', linewidth=1, color='black')\n",
    "plt.xticks(range(1, 6), [f'Template {i}' for i in range(1, 5)] + ['Mean'], rotation=45)\n",
    "plt.xlim(0.75, 6.5)\n",
    "plt.ylabel('$g_s$ - stereotype rate')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/en_templates.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398efedb-6ffe-43c9-8c04-b2f3f059951a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Template correlations.\n",
    "\n",
    "The correlations are quite strong (0.6+). Correlations between templates that use the same words (X he said, He said X) are much stronger.\n",
    "This shows certain lexical consistency, that is not the same when we change the gender identifier (he > the man).\n",
    "\"\"\"\n",
    "corrs = []\n",
    "for model in models:\n",
    "    results = np.vstack(\n",
    "        r_is(model_template_file(model, template_id), bootstrap=False)\n",
    "        for template_id in range(4)\n",
    "    )\n",
    "    corr = np.corrcoef(results)\n",
    "    corrs.append(corr)\n",
    "    plt.title(f'Model {model}')\n",
    "    visualize_corr(corr)\n",
    "\n",
    "mean_corrs = np.mean(np.array(corrs), axis=0)\n",
    "plt.title(f'Model mean')\n",
    "visualize_corr(mean_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e5d01-bf32-45d8-b20d-d04bf67b5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model correlations.\n",
    "\n",
    "How the results correlate between models. The correlations are weaker overall (0.5), and they do not say that much.\n",
    "Only visible pattern is that MBERT is less correlated to the other models.\n",
    "\"\"\"\n",
    "\n",
    "corrs = []\n",
    "for template_id in range(4):\n",
    "    results = np.vstack(\n",
    "        r_is(model_template_file(model, template_id), bootstrap=False)\n",
    "        for model in models\n",
    "    )\n",
    "    corr = np.corrcoef(results)\n",
    "    plt.title(f'Template {template_id}')\n",
    "    visualize_corr(corr)\n",
    "    corrs.append(corr)\n",
    "\n",
    "mean_corr = np.mean(np.array(corrs), axis=0)\n",
    "plt.title(f'Template mean')\n",
    "visualize_corr(mean_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5678d-3612-4ebf-a05c-1156e50a3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some (model, template) combinations show either masculine or feminine preference. The stereotypical reasoning is similar in\n",
    "all of them (the lines are similar), but the base rate (masculine/feminine preference) is different.\n",
    "\"\"\"\n",
    "plt.rcParams[\"figure.figsize\"] = (10,4)\n",
    "\n",
    "_, axes = plt.subplots(1, 2)\n",
    "\n",
    "for model, template_id in product(models, range(4)):\n",
    "    arr = r_is(model_template_file(model, template_id), bootstrap=False)\n",
    "    arr = np.array(arr)\n",
    "    axes[0].plot(arr, c='black', linestyle=':', linewidth=1)\n",
    "    arr -= min(arr)\n",
    "    arr /= max(arr)\n",
    "    axes[1].plot(arr, c='black', linestyle=':', linewidth=1)\n",
    "axes[0].set_title('Raw')\n",
    "axes[1].set_title('Normalized')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de4a16-83d7-40e1-9e84-bed8b9a7ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boxplot of positions (the rank in the list of 16 stereotypes) for all stereotypes.\n",
    "\"\"\"\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)\n",
    "\n",
    "ranks = np.vstack([\n",
    "    r_i_ranks(model_template_file(model, template_id))\n",
    "    for model in models\n",
    "    for template_id in range(4)\n",
    "])\n",
    "plt.boxplot([ranks[:,i] for i in range(16)], vert=False, sym='.')\n",
    "plt.axhline(7.5, c='black', linestyle=':')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xticks(range(1,17))\n",
    "plt.yticks(range(1,17), stereotype_names)\n",
    "plt.xlabel('Feminine rank')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/en_ranks.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d86dc-8680-46c7-9949-7a851f27dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Boxplots for templates. They look pretty similar to each other. \"he/she\" templates are more consistent than \"man/woman\".\n",
    "\"\"\"\n",
    "plt.rcParams[\"figure.figsize\"] = (5,4)\n",
    "\n",
    "for template_id in range(4):\n",
    "    ranks = np.vstack([\n",
    "        r_i_ranks(model_template_file(model, template_id))\n",
    "        for model in models\n",
    "    ])\n",
    "    plt.boxplot([ranks[:,i] for i in range(16)], vert=False, sym='.')\n",
    "    plt.axhline(7.5, c='black', linestyle=':')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xticks(range(1,17))\n",
    "    plt.yticks(range(1,17), stereotype_names)\n",
    "    plt.xlabel('Feminine rank')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54493e6a-59a7-44e7-8330-df3b1dca14c5",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "Correlations calculated across scores for individual instances `instance_results` and score for stereotypes `r_i_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe377b99-f01e-4d04-b037-2c98a972d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_results = {\n",
    "    (model, template_id): file_results(model_template_file(model, template_id))\n",
    "    for model, template_id in product(models, range(4))\n",
    "}\n",
    "r_i_results = {\n",
    "    (model, template_id): r_is(model_template_file(model, template_id), bootstrap=False)\n",
    "    for model, template_id in product(models, range(4))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa91068-b033-472a-bab2-ae99f19f6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean correlation between models\n",
    "\"\"\"\n",
    "(\n",
    "    np.mean([\n",
    "        np.mean([\n",
    "            pearsonr(instance_results[model1, template], instance_results[model2, template])[0]\n",
    "            for model1, model2 in combinations(models, 2)\n",
    "        ])\n",
    "        for template in range(4)\n",
    "    ]),\n",
    "    \n",
    "    np.mean([\n",
    "        np.mean([\n",
    "            pearsonr(r_i_results[model1, template], r_i_results[model2, template])[0]\n",
    "            for model1, model2 in combinations(models, 2)\n",
    "        ])\n",
    "        for template in range(4)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81c22f-8249-45d4-82bc-29b599a7b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean correlation between templates\n",
    "\"\"\"\n",
    "(\n",
    "    np.mean([\n",
    "        np.mean([\n",
    "            pearsonr(instance_results[model, template1], instance_results[model, template2])[0]\n",
    "            for template1, template2 in combinations(range(4), 2)\n",
    "        ])\n",
    "        for model in models\n",
    "    ]),\n",
    "    \n",
    "    np.mean([\n",
    "        np.mean([\n",
    "            pearsonr(r_i_results[model, template1], r_i_results[model, template2])[0]\n",
    "            for template1, template2 in combinations(range(4), 2)\n",
    "        ])\n",
    "        for model in models\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610bbd91-3af0-42c9-ac5e-c34913554fc3",
   "metadata": {},
   "source": [
    "## MultiBERT\n",
    "\n",
    "We do not include the predictions calculated for MultiBERT within the repository due to its size (50MB), but the inference code is available. The predictions are also available upon request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe78ee4-c3f8-41b3-a531-ede34aba9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evolution during a BERT training run. Seems pretty consistent after the initial spike.\n",
    "\n",
    "Template #3 is a bit lower, similar to how it behaves for regular BERT in Figure 4. This suggest that the drop there\n",
    "is somehow connected to the data.\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "pred_files = glob.glob('./cache/predictions/multibert/*seed_0*')\n",
    "steps = sorted(set(\n",
    "    int(re.findall(r'([0-9]+)k', filename)[0])\n",
    "    for filename in pred_files\n",
    "    if 'k' in filename\n",
    "))\n",
    "\n",
    "def multibert_filename(seed_id, step_count, template_id):\n",
    "    return f'./cache/predictions/multibert/multiberts-seed_{seed_id}-step_{step_count}k_template-{template_id}.txt'\n",
    "\n",
    "\n",
    "for template_id in range(4):\n",
    "    for seed_id in range(5):\n",
    "        plt.plot(\n",
    "            steps,\n",
    "            [\n",
    "                g_s(multibert_filename(seed_id, step, template_id))\n",
    "                for step in steps\n",
    "            ]\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f85da-163c-4509-b0ed-4d987b858cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Correlation of the scores for individual checkpoints.\n",
    "\"\"\"\n",
    "results = np.vstack(\n",
    "    file_results(multibert_filename(0, step, 0))\n",
    "    for step in steps\n",
    ")\n",
    "corr = np.corrcoef(results)\n",
    "visualize_corr(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a745be-27be-4de0-8147-d0ae27215b7a",
   "metadata": {},
   "source": [
    "## Family-related terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c22cd01-7876-41aa-bab5-a083f217eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_words = 'family child children partner kids kid family\\'s'.split()\n",
    "\n",
    "def family_rate(filename):\n",
    "    return np.mean([\n",
    "        val\n",
    "        for val, sentence, stereotype_id in zip(file_results(filename), gest.sentence, gest.stereotype)\n",
    "        if any(word in sentence for word in family_words) and stereotype_id > 7\n",
    "    ])\n",
    "\n",
    "al, bl, cl = [], [], []\n",
    "for i, (model, template_id) in enumerate(product(models, range(4))):\n",
    "    filename = model_template_file(model, template_id)\n",
    "    a, b, c = r_m(filename), r_f(filename), family_rate(filename)\n",
    "    plt.scatter([a], [i], c='lightblue')\n",
    "    plt.scatter([b], [i], c='pink')\n",
    "    plt.scatter([c], [i], c='green')\n",
    "    al.append(a); bl.append(b); cl.append(c)\n",
    "print(np.mean(al), np.mean(bl), np.mean(cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786e350-5133-450b-be48-dec052e65d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
